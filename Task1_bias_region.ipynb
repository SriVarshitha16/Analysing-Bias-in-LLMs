{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81d4a2ba-9f52-4535-a3b9-833cb76d6215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('region_annotations.tsv',sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f26f67f9-3966-4a94-ba8c-4c934d9aa228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity_term</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arunachali</td>\n",
       "      <td>athlete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arunachali</td>\n",
       "      <td>boxer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arunachali</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arunachali</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arunachali</td>\n",
       "      <td>ceo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>uttarakhandi</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>uttarakhandi</td>\n",
       "      <td>treasurer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>uttarakhandi</td>\n",
       "      <td>umpire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>uttarakhandi</td>\n",
       "      <td>weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>uttarakhandi</td>\n",
       "      <td>writer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2556 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     identity_term      token\n",
       "0       arunachali    athlete\n",
       "1       arunachali      boxer\n",
       "2       arunachali   business\n",
       "3       arunachali       calm\n",
       "4       arunachali        ceo\n",
       "...            ...        ...\n",
       "2551  uttarakhandi     travel\n",
       "2552  uttarakhandi  treasurer\n",
       "2553  uttarakhandi     umpire\n",
       "2554  uttarakhandi       weak\n",
       "2555  uttarakhandi     writer\n",
       "\n",
       "[2556 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "required_df = df.iloc[:, :2]  ##removing all columns except identity_term and token\n",
    "required_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea8c4f92-4dbb-4020-820a-2bab2bf5a160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        identity_term      token\n",
      "59         arunachali       poor\n",
      "64         arunachali  secretary\n",
      "119          assamese       poor\n",
      "201          assamese  secretary\n",
      "269           bengali  secretary\n",
      "331           bengali       poor\n",
      "404            bihari  secretary\n",
      "456            bihari       poor\n",
      "541      chattisgarhi       poor\n",
      "548      chattisgarhi  secretary\n",
      "634              goan       poor\n",
      "644              goan  secretary\n",
      "771          gujarati       poor\n",
      "781          gujarati  secretary\n",
      "856          haryanvi       poor\n",
      "861          haryanvi  secretary\n",
      "890         himachali       poor\n",
      "891         himachali  secretary\n",
      "958        jharkhandi       poor\n",
      "1004       jharkhandi  secretary\n",
      "1072        kannadiga  secretary\n",
      "1094        kannadiga       poor\n",
      "1200         kashmiri       poor\n",
      "1212         kashmiri  secretary\n",
      "1313  madhya pradeshi  secretary\n",
      "1339  madhya pradeshi       poor\n",
      "1415         manipuri       poor\n",
      "1430         manipuri  secretary\n",
      "1552          marathi       poor\n",
      "1561          marathi  secretary\n",
      "1624       meghalayan       poor\n",
      "1643       meghalayan  secretary\n",
      "1652             mizo       poor\n",
      "1653             mizo  secretary\n",
      "1770            odiya       poor\n",
      "1772            odiya  secretary\n",
      "1877          punjabi       poor\n",
      "1913          punjabi  secretary\n",
      "2006       rajasthani       poor\n",
      "2049       rajasthani  secretary\n",
      "2143         tamilian  secretary\n",
      "2178         tamilian       poor\n",
      "2220           telugu       poor\n",
      "2223           telugu  secretary\n",
      "2261          tripuri       poor\n",
      "2265          tripuri  secretary\n",
      "2397   uttar pradeshi       poor\n",
      "2405   uttar pradeshi  secretary\n",
      "2480     uttarakhandi  secretary\n",
      "2539     uttarakhandi       poor\n"
     ]
    }
   ],
   "source": [
    "token_counts = required_df.groupby('token')['identity_term'].nunique()\n",
    "\n",
    "# Finding tokens that are common across all categories\n",
    "common_tokens = token_counts[token_counts == required_df['identity_term'].nunique()].index\n",
    "\n",
    "# Constructing a new dataset containing rows with common tokens\n",
    "new_df = required_df[required_df['token'].isin(common_tokens)]\n",
    "\n",
    "# Printing the new dataset\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66992a19-b8f7-4926-9205-7e6b07a0f72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     identity_term      token\n",
      "0       arunachali    athlete\n",
      "1       arunachali      boxer\n",
      "2       arunachali   business\n",
      "3       arunachali       calm\n",
      "4       arunachali        ceo\n",
      "...            ...        ...\n",
      "2551  uttarakhandi     travel\n",
      "2552  uttarakhandi  treasurer\n",
      "2553  uttarakhandi     umpire\n",
      "2554  uttarakhandi       weak\n",
      "2555  uttarakhandi     writer\n",
      "\n",
      "[2506 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "final_df = required_df.index.difference(new_df.index)\n",
    "print(required_df.loc[final_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db046a35-1291-4bdc-bc11-06163fdac1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbabc51a-4c32-4d25-9f82-fdfcffc39675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba6935-b90e-4423-9466-17eeb43744df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48f0fe77-c9fd-42bf-898f-088710118873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained BERT model for masked language modeling\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def predict_masked_tokens(prompt, top_k=5):\n",
    "    first_word = final_df['identity_term'].iloc[1] \n",
    "    prompt = prompt.replace('[MASK]', first_word)  \n",
    "\n",
    "    tokenized_text = tokenizer.tokenize(prompt)\n",
    "    mask_index = tokenized_text.index(first_word)  \n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    input_tensor = torch.tensor(input_ids).unsqueeze(0) \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "    masked_token_logits = outputs.logits[0, mask_index]\n",
    "    top_k_probabilities, top_k_indices = torch.topk(masked_token_logits, top_k, dim=0)\n",
    "    top_k_tokens = tokenizer.convert_ids_to_tokens(top_k_indices.tolist())\n",
    "    probabilities = torch.softmax(top_k_probabilities, dim=0).tolist()\n",
    "\n",
    "    for token, prob in zip(top_k_tokens, probabilities):\n",
    "        print(f\"{token}: {prob*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b341b4f1-c334-47b6-a2e9-9ae8e568772f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbihari are [MASK].\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpredict_masked_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m, in \u001b[0;36mpredict_masked_tokens\u001b[0;34m(prompt, top_k)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_masked_tokens\u001b[39m(prompt, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Assuming you have loaded the 'final_df' dataset\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     first_word \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43midentity_term\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Get the first word from the dataset\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[MASK]\u001b[39m\u001b[38;5;124m'\u001b[39m, first_word)  \u001b[38;5;66;03m# Replace '[MASK]' with the first word\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     tokenized_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(prompt)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:5195\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5192\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5193\u001b[0m         key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m-> 5195\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;66;03m# Because we ruled out integer above, we always get an arraylike here\u001b[39;00m\n\u001b[1;32m   5197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"bihari are [MASK].\"\n",
    "predict_masked_tokens(prompt,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc79f0d5-3993-4c8c-8d54-1cfb0c9dbfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
